{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import __future__\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from numpy import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig(z):\n",
    "    \"\"\"Sigmoid function.\"\"\"\n",
    "    return (1.0 / (1.0 + np.exp(-z)))\n",
    "\n",
    "def d_sig(z):\n",
    "    \"\"\"First derivative of the sigmoid function.\"\"\"\n",
    "    return (sig(z) * (1 - sig(z)))\n",
    "\n",
    "def inv_sig(x):\n",
    "    \"\"\"Inverse of the sigmoid function.\"\"\"\n",
    "    return np.array([np.log(1 / (1/xi - 1)) for xi in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin(z):\n",
    "    \"\"\"Linear function.\"\"\"\n",
    "    return (z)\n",
    "\n",
    "def d_lin(z):\n",
    "    \"\"\"First derivative of the linear function.\"\"\"\n",
    "    return(1)\n",
    "\n",
    "def inv_lin(x):\n",
    "    \"\"\"Inverse of the linear function.\"\"\"\n",
    "    return (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrelu(z, leak = 0.01):\n",
    "    \"\"\"Leaky rectified linear unit (leaky ReLU).\"\"\"\n",
    "    z[z < 0] *= leak\n",
    "    return(z)\n",
    "\n",
    "def d_lrelu(z, leak = 0.01):\n",
    "    \"\"\"First derivative of the leaky ReLU function,\n",
    "    which can be represented by the Heaviside step function.\"\"\"\n",
    "    z[z >= 0] = 1\n",
    "    z[z < 0] = leak\n",
    "    return(z)\n",
    "\n",
    "def inv_lrelu(x, leak = 0.01):\n",
    "    \"\"\"Inverse of the leaky ReLU function.\"\"\" \n",
    "    x[x < 0] *= 1/leak\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArtificialNeuralNetwork(object):\n",
    "    \"\"\"An artificial neural network.\"\"\"\n",
    "    \n",
    "    def __init__(self, layers, cross_entropy = False, act = sig, d_act = d_sig, inv_act = inv_sig):\n",
    "        \"\"\"Initialize the ANN class by randomizing all the\n",
    "        weights and biases in the network.\n",
    "        \n",
    "        `layers`: (list) list whose elements are the number of neurons in each\n",
    "        layer; (list of integers)\n",
    "        \n",
    "        `num_layers`: (integer) number of layers in the network including \n",
    "        input layer, given by the length of `layers` list.\n",
    "        \n",
    "        `biases`: (list) list of column vectors containing randomized biases.\n",
    "        No biases for the 0th (input) layer; (list of arrays)\n",
    "        \n",
    "        `weights`: (list) list of matrices containing randomized weights.\n",
    "        The matrix dimensions are (ml, ml_1), where ml is the number of \n",
    "        neurons in the next/terminal layer and ml_1 (em el minus one) is the \n",
    "        number of neurons in the previous/initial layer; (list of arrays)\"\"\"\n",
    "        \n",
    "        self.layers = layers\n",
    "        self.num_layers = len(layers)\n",
    "        self.biases = [random.randn(ml, 1) for ml in layers[1:]]  \n",
    "        self.weights = [random.randn(ml, ml_1)/np.sqrt(ml_1)\n",
    "                        for (ml, ml_1) in zip(layers[1:], layers[:-1])]  # implemented weight initialization\n",
    "        self.cross_entropy = cross_entropy\n",
    "        self.act = act\n",
    "        self.d_act = d_act\n",
    "        self.inv_act = inv_act\n",
    "    \n",
    "    \n",
    "    def feedforward(self, x):\n",
    "        \"\"\"Secondly, define the input values and feed them forward. This\n",
    "        function returns the activation values and weighted inputs of the \n",
    "        next layer given the weighted input values of the previous layer,\n",
    "        which is `x`. Done by using the sigmoid activation function.\n",
    "        \n",
    "        `x`: (array) input values of the first layer.\"\"\"\n",
    "        \n",
    "        weighted_inputs = []\n",
    "        activations = [x]\n",
    "        \n",
    "        for (b, w) in zip(self.biases, self.weights):\n",
    "            z = np.dot(w, x) + b\n",
    "            x = self.act(z)\n",
    "            weighted_inputs.append(z)\n",
    "            activations.append(x)\n",
    "            \n",
    "        return (weighted_inputs, activations)\n",
    "    \n",
    "    \n",
    "    def cost_derivative(self, xL, y):\n",
    "        \"\"\"After feeding forward, we will have activation values of all\n",
    "        the layers. This function returns the derivative of the cost \n",
    "        function with respect to the output activation in the last layer. \n",
    "        \n",
    "        `xL`: (array) should ONLY be activation values of the last layer.\n",
    "        \n",
    "        `y`: (array) target output values.\"\"\"\n",
    "        \n",
    "        #if self.cross_entropy:\n",
    "        #    return ((xL - y) / (xL*(1 - xL)))\n",
    "        #else:\n",
    "        return (xL - y)\n",
    "    \n",
    "    \n",
    "    def backpropagate(self, x, y):\n",
    "        \"\"\"Using the weighted inputs and activation values from feeding \n",
    "        forward, we now backpropagate the errors from each layer, starting\n",
    "        from the last layer. After the errors are backpropagated, the \n",
    "        gradients of cost with respect to each weight and bias is computed.\n",
    "        The function then returns the two lists of gradients as a tuple.\n",
    "        \n",
    "        `x`: (array) input values of the first layer.\n",
    "        \n",
    "        `y`: (array) target output values.\"\"\"\n",
    "        \n",
    "        (Z, X) = self.feedforward(x)\n",
    "        L = self.num_layers - 1  # python's index of the last layer, first layer is 0th layer\n",
    "        gradients_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        gradients_w = [np.zeros(w.shape) for w in self.biases]\n",
    "        \n",
    "        grad_xL = self.cost_derivative(X[L], y)\n",
    "        \n",
    "        if self.cross_entropy:\n",
    "            delta_l = grad_xL\n",
    "        else:\n",
    "            dsig_zL = self.d_act(Z[L-1])\n",
    "            delta_l = grad_xL * dsig_zL # compute output error ; numpy multiplication is elementwise\n",
    "            \n",
    "        grad_wL = np.dot(delta_l, X[L-1].transpose())\n",
    "        \n",
    "        gradients_b[L-1] = delta_l\n",
    "        gradients_w[L-1] = grad_wL\n",
    "        \n",
    "        for l in range(L-1,0,-1): # backpropagate the error, starting from the second last layer\n",
    "            \n",
    "            dsig_zl = self.d_act(Z[l-1])\n",
    "            delta_l = np.dot(self.weights[l].transpose(), delta_l) * dsig_zl    \n",
    "            grad_wl = np.dot(delta_l, X[l-1].transpose())\n",
    "            \n",
    "            gradients_b[l-1] = delta_l\n",
    "            gradients_w[l-1] = grad_wl\n",
    "        \n",
    "        return(gradients_b, gradients_w)\n",
    "    \n",
    "    \n",
    "    def SGD(self, mini_batch, alpha, lmbda, n):\n",
    "        \"\"\"Using the gradients calculated from the backpropagation problem,\n",
    "        we apply one step of the stochastic gradient descent algorithm to a\n",
    "        single mini-batch of data.\n",
    "        \n",
    "        `mini_batch`: (list of tuples)\n",
    "        \n",
    "        `alpha`: (integer) learning rate.\"\"\"\n",
    "        \n",
    "        grad_b_sum = [np.zeros(b.shape) for b in self.biases]\n",
    "        grad_w_sum = [np.zeros(w.shape) for w in self.weights]\n",
    "        \n",
    "        for (qx, qy) in mini_batch:  # here, a matrix-based approach can be taken\n",
    "            (grad_bq, grad_wq) = self.backpropagate(qx, qy)\n",
    "            grad_b_sum = [gb + gbq for (gb, gbq) in zip(grad_b_sum, grad_bq)]\n",
    "            grad_w_sum = [gw + gwq for (gw, gwq) in zip(grad_w_sum, grad_wq)]\n",
    "           \n",
    "        new_biases = [b - (alpha / len(mini_batch)) * gbs  \n",
    "                      for (b, gbs) in zip(self.biases, grad_b_sum)]\n",
    "        new_weights = [(1 - alpha*lmbda/n)*w - (alpha / len(mini_batch)) * gws\n",
    "                       for (w, gws) in zip(self.weights, grad_w_sum)]\n",
    "        \n",
    "        self.biases = new_biases\n",
    "        self.weights = new_weights\n",
    "        \n",
    "        return([new_biases, new_weights])\n",
    "        \n",
    "        \n",
    "    def evaluate(self, test):\n",
    "        \"\"\"Return the number of test inputs for which the neural network\n",
    "        outputs the correct result. The neural network's output is \n",
    "        calculated by taking the index of the neuron with the highest\n",
    "        activation value in the final layer.\n",
    "        \n",
    "        `test`: (list of tuples)\"\"\"\n",
    "        \n",
    "        test_results = [(self.feedforward(x)[1][-1], \n",
    "                         np.argmax(y)) for (x, y) in test]\n",
    "    \n",
    "        return (sum(int(np.argmax(xL) == yi) \n",
    "                    for (xL, yi) in test_results))\n",
    "    \n",
    "    \n",
    "    def track_progress(self, train, mini_batch_size, alpha, epochs,\n",
    "                       lmbda, test = None):\n",
    "        \"\"\"applies SGD over all batches and epochs\n",
    "        \n",
    "        `train`: (list of tuples)\n",
    "        \n",
    "        `mini_batch_size`: (integer)\n",
    "        \n",
    "        `alpha`: (integer)\n",
    "        \n",
    "        `epochs`: (integer)\n",
    "        \n",
    "        `test`: (list of tuples).\"\"\"\n",
    "        \n",
    "        wei = []\n",
    "        bia = []\n",
    "        if test: n_test = len(test)\n",
    "        n = len(train)\n",
    "        \n",
    "        for j in range(epochs):  # change here to implement matrix-based approach\n",
    "            random.shuffle(train)\n",
    "            #random.shuffle(test)\n",
    "            mini_batches = [train[k:k+mini_batch_size]\n",
    "                            for k in range(0, n, mini_batch_size)]\n",
    "            for mini_batch in mini_batches:\n",
    "                sgd = self.SGD(mini_batch, alpha, lmbda, n)\n",
    "                bia = sgd[0]\n",
    "                wei = sgd[1]\n",
    "                \n",
    "            if test: # with %d(%g)%% confidence\"\n",
    "                print(\"Epoch %d: %d / %d\"  % (j+1,\n",
    "                      self.evaluate(test), n_test))\n",
    "                    #, self.evaluate(test)[1], self.evaluate(test)[2]))\n",
    "            else:\n",
    "                print(\"Epoch %d complete\" % (j+1,))\n",
    "        \n",
    "        return([bia, wei])\n",
    "            #display(self.evaluate(test)[1])\n",
    "    \n",
    "    \n",
    "    def collect_parameters(self, train, mini_batch_size, alpha, epochs, lmbda, test = None):\n",
    "        \n",
    "        \n",
    "        tp = self.track_progress(train, mini_batch_size, alpha, epochs,\n",
    "                       lmbda, test)\n",
    "        \n",
    "        self.bee = tp[0]\n",
    "        self.Wu = tp[1]\n",
    "        \n",
    "    \n",
    "    def write(self, number):\n",
    "        \n",
    "        \n",
    "        L = self.num_layers - 1  \n",
    "        condition = (np.arange(self.layers[-1]) == number)\n",
    "        y0 = (condition * 1.).reshape(self.layers[-1],1)\n",
    "        y = (condition * 1.).reshape(self.layers[-1],1)\n",
    "        \n",
    "        b = self.bee\n",
    "        W = self.Wu\n",
    "        \n",
    "        for k in range(L-1,-1,-1):\n",
    "            \n",
    "            z = self.inv_act(y)\n",
    "            inv_Wk = np.linalg.pinv(W[k])\n",
    "            y = np.matmul(inv_Wk, (z - b[k]))\n",
    "        \n",
    "        y = y.reshape((28, 28))\n",
    "        return(y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train scribe\n",
    "scribe = ArtificialNeuralNetwork([784, 100, 10], cross_entropy = True, act = lrelu, d_act = d_lrelu, inv_act = inv_lrelu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 9527 / 10000\n",
      "Epoch 2: 9574 / 10000\n",
      "Epoch 3: 9629 / 10000\n",
      "Epoch 4: 9668 / 10000\n",
      "Epoch 5: 9688 / 10000\n",
      "Epoch 6: 9704 / 10000\n",
      "Epoch 7: 9705 / 10000\n",
      "Epoch 8: 9728 / 10000\n",
      "Epoch 9: 9731 / 10000\n",
      "Epoch 10: 9737 / 10000\n",
      "Epoch 11: 9739 / 10000\n",
      "Epoch 12: 9753 / 10000\n",
      "Epoch 13: 9738 / 10000\n",
      "Epoch 14: 9747 / 10000\n",
      "Epoch 15: 9757 / 10000\n",
      "Epoch 16: 9754 / 10000\n",
      "Epoch 17: 9757 / 10000\n",
      "Epoch 18: 9770 / 10000\n",
      "Epoch 19: 9756 / 10000\n",
      "Epoch 20: 9743 / 10000\n",
      "Epoch 21: 9764 / 10000\n",
      "Epoch 22: 9746 / 10000\n",
      "Epoch 23: 9764 / 10000\n",
      "Epoch 24: 9786 / 10000\n",
      "Epoch 25: 9775 / 10000\n",
      "Epoch 26: 9772 / 10000\n",
      "Epoch 27: 9765 / 10000\n",
      "Epoch 28: 9754 / 10000\n",
      "Epoch 29: 9756 / 10000\n",
      "Epoch 30: 9774 / 10000\n"
     ]
    }
   ],
   "source": [
    "scribe.collect_parameters(train = mnist_train, mini_batch_size = 10, alpha = 0.1, epochs = 30, lmbda = 5.0, test = mnist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x235928550f0>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 0\n",
    "plt.imshow((scribe.write(number = n) - np.mean(scribe.write(number = n))) / np.std(scribe.write(number = n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = ArtificialNeuralNetwork([3,4,10], cross_entropy = True, act = lin, d_act = d_lin, inv_act = inv_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.68416171],\n",
       "       [-21.42131728],\n",
       "       [ -5.68693583]])"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.write(number = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.90810384],\n",
       "        [-0.49645192],\n",
       "        [ 0.26527173],\n",
       "        [ 0.45500425]]), array([[-0.38368716],\n",
       "        [-0.99846356]])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.65924387,  0.36517461,  1.13463437],\n",
       "        [-1.09100389, -0.51929066, -0.02437729],\n",
       "        [-0.14103196,  0.35366232, -0.24706775],\n",
       "        [ 0.25404798, -0.48978494, -0.39120683]]),\n",
       " array([[-0.06468083,  0.19356078,  0.51588592, -0.07810771],\n",
       "        [ 1.01984022, -0.70366111, -0.23453442,  0.85547845]])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [2, 8, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "annlogic = ArtificialNeuralNetwork(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "and_inp = [(np.array([[0],[0]]), np.array([[1],[0]])),\n",
    "           (np.array([[0],[1]]), np.array([[0],[1]])),\n",
    "           (np.array([[1],[0]]), np.array([[0],[1]])),\n",
    "           (np.array([[1],[1]]), np.array([[1],[0]]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(80):\n",
    "    for inp in and_inp:\n",
    "        new_tup = tuple(inp)\n",
    "        train_data.append(new_tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "annlogic.track_progress(train = train_data, mini_batch_size = 2, alpha = 0.1, epochs = 100, test = test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-1a516c502833>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.contrib.learn.python.learn.datasets.base.Datasets"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# special dataset type\n",
    "type(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 55000 images and 784 pixels in each image\n",
    "# each image is places as a row\n",
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10000 test examples\n",
    "mnist.test.num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can understand images like this ; grab the 1st image and reshape into 28x28\n",
    "mnist.train.images[1].reshape((28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x288dda65c88>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# then call the imshow() method from matplotlib\n",
    "# and then change colormap into greyscale\n",
    "plt.imshow(mnist.train.images[1].reshape((28,28)), cmap = 'gist_gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist.train.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 10)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## process raw data into train and test lists of tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2,3],\n",
    "              [4,5,6],\n",
    "              [7,8,9],\n",
    "              [10,11,12],\n",
    "              [13,14,15]])\n",
    "b = np.array([[11,22],\n",
    "              [33,44],\n",
    "              [55,66],\n",
    "              [77,88],\n",
    "              [99,101]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_lis = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([[1],\n",
       "         [2],\n",
       "         [3]]), array([[11],\n",
       "         [22]])), (array([[4],\n",
       "         [5],\n",
       "         [6]]), array([[33],\n",
       "         [44]])), (array([[7],\n",
       "         [8],\n",
       "         [9]]), array([[55],\n",
       "         [66]])), (array([[10],\n",
       "         [11],\n",
       "         [12]]), array([[77],\n",
       "         [88]])), (array([[13],\n",
       "         [14],\n",
       "         [15]]), array([[ 99],\n",
       "         [101]]))]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for (ai,bi) in zip(a,b):\n",
    "    emp_lis.append((ai.reshape(3,1),\n",
    "                    bi.reshape(2,1)))\n",
    "emp_lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data_inputs, data_labels):\n",
    "    \"\"\"Function to package data into a list of tuples\n",
    "    consisting of input data and target output arrays. \n",
    "    Returns a list of data tuples.\n",
    "    \n",
    "    `data_inputs`: (2D array)\n",
    "    \n",
    "    `data_labels`: (2D array).\"\"\"\n",
    "    \n",
    "    input_col = data_inputs.shape[1]\n",
    "    label_col = data_labels.shape[1]\n",
    "    data_list = []\n",
    "    \n",
    "    for (di,dl) in zip(data_inputs, data_labels):\n",
    "        data_list.append((di.reshape(input_col,1),\n",
    "                          dl.reshape(label_col,1)))\n",
    "    \n",
    "    return (data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = mnist.train.images\n",
    "train_labels = mnist.train.labels\n",
    "\n",
    "mnist_train = process_data(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = mnist.test.images\n",
    "test_labels = mnist.test.labels\n",
    "\n",
    "mnist_test = process_data(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process validation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_images = mnist.validation.images\n",
    "validation_labels = mnist.validation.labels\n",
    "\n",
    "mnist_validation = process_data(validation_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_mnist = ArtificialNeuralNetwork([784, 30, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 9113 / 10000\n",
      "Epoch 1: 9221 / 10000\n",
      "Epoch 2: 9330 / 10000\n",
      "Epoch 3: 9385 / 10000\n",
      "Epoch 4: 9410 / 10000\n",
      "Epoch 5: 9403 / 10000\n",
      "Epoch 6: 9429 / 10000\n",
      "Epoch 7: 9415 / 10000\n",
      "Epoch 8: 9445 / 10000\n",
      "Epoch 9: 9457 / 10000\n",
      "Epoch 10: 9448 / 10000\n",
      "Epoch 11: 9487 / 10000\n",
      "Epoch 12: 9457 / 10000\n",
      "Epoch 13: 9495 / 10000\n",
      "Epoch 14: 9470 / 10000\n",
      "Epoch 15: 9475 / 10000\n",
      "Epoch 16: 9470 / 10000\n",
      "Epoch 17: 9500 / 10000\n",
      "Epoch 18: 9496 / 10000\n",
      "Epoch 19: 9507 / 10000\n",
      "Epoch 20: 9490 / 10000\n",
      "Epoch 21: 9499 / 10000\n",
      "Epoch 22: 9491 / 10000\n",
      "Epoch 23: 9499 / 10000\n",
      "Epoch 24: 9511 / 10000\n",
      "Epoch 25: 9492 / 10000\n",
      "Epoch 26: 9485 / 10000\n",
      "Epoch 27: 9515 / 10000\n",
      "Epoch 28: 9486 / 10000\n",
      "Epoch 29: 9525 / 10000\n"
     ]
    }
   ],
   "source": [
    "ann_mnist.track_progress(train = mnist_train, mini_batch_size = 10, alpha = 3.0, epochs = 30, test = mnist_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. peak accuracy 95.25% when run on a [784, 30, 10] network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_mnist2 = ArtificialNeuralNetwork([784, 100, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 6681 / 10000\n",
      "Epoch 1: 7504 / 10000\n",
      "Epoch 2: 8427 / 10000\n",
      "Epoch 3: 8490 / 10000\n",
      "Epoch 4: 8541 / 10000\n",
      "Epoch 5: 8591 / 10000\n",
      "Epoch 6: 8596 / 10000\n",
      "Epoch 7: 9521 / 10000\n",
      "Epoch 8: 9533 / 10000\n",
      "Epoch 9: 9584 / 10000\n",
      "Epoch 10: 9573 / 10000\n",
      "Epoch 11: 9601 / 10000\n",
      "Epoch 12: 9604 / 10000\n",
      "Epoch 13: 9625 / 10000\n",
      "Epoch 14: 9630 / 10000\n",
      "Epoch 15: 9634 / 10000\n",
      "Epoch 16: 9634 / 10000\n",
      "Epoch 17: 9640 / 10000\n",
      "Epoch 18: 9658 / 10000\n",
      "Epoch 19: 9654 / 10000\n",
      "Epoch 20: 9652 / 10000\n",
      "Epoch 21: 9655 / 10000\n",
      "Epoch 22: 9655 / 10000\n",
      "Epoch 23: 9661 / 10000\n",
      "Epoch 24: 9662 / 10000\n",
      "Epoch 25: 9666 / 10000\n",
      "Epoch 26: 9672 / 10000\n",
      "Epoch 27: 9678 / 10000\n",
      "Epoch 28: 9671 / 10000\n",
      "Epoch 29: 9673 / 10000\n"
     ]
    }
   ],
   "source": [
    "ann_mnist2.track_progress(train = mnist_train, mini_batch_size = 10, alpha = 3.0, epochs = 30, test = mnist_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. peak accuracy 96.78% when run on a [784, 100, 10] network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_mnist3 = ArtificialNeuralNetwork([784, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 6444 / 10000\n",
      "Epoch 1: 7172 / 10000\n",
      "Epoch 2: 7221 / 10000\n",
      "Epoch 3: 7250 / 10000\n",
      "Epoch 4: 7219 / 10000\n",
      "Epoch 5: 7264 / 10000\n",
      "Epoch 6: 7262 / 10000\n",
      "Epoch 7: 7280 / 10000\n",
      "Epoch 8: 7272 / 10000\n",
      "Epoch 9: 7282 / 10000\n",
      "Epoch 10: 7269 / 10000\n",
      "Epoch 11: 7291 / 10000\n",
      "Epoch 12: 7270 / 10000\n",
      "Epoch 13: 7297 / 10000\n",
      "Epoch 14: 7285 / 10000\n",
      "Epoch 15: 7285 / 10000\n",
      "Epoch 16: 7273 / 10000\n",
      "Epoch 17: 7290 / 10000\n",
      "Epoch 18: 7277 / 10000\n",
      "Epoch 19: 7293 / 10000\n",
      "Epoch 20: 7287 / 10000\n",
      "Epoch 21: 7294 / 10000\n",
      "Epoch 22: 7299 / 10000\n",
      "Epoch 23: 7313 / 10000\n",
      "Epoch 24: 7272 / 10000\n",
      "Epoch 25: 7285 / 10000\n",
      "Epoch 26: 7281 / 10000\n",
      "Epoch 27: 7270 / 10000\n",
      "Epoch 28: 7289 / 10000\n",
      "Epoch 29: 7306 / 10000\n"
     ]
    }
   ],
   "source": [
    "ann_mnist3.track_progress(train = mnist_train, mini_batch_size = 10, alpha = 3.0, epochs = 30, test = mnist_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. peak accuracy 73.13% when run on a [784, 10] network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_mnist4 = ArtificialNeuralNetwork([784, 200, 150, 100, 10]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WARNING: very long execution time, takes 2.5 min per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 7191 / 10000\n",
      "Epoch 1: 7387 / 10000\n",
      "Epoch 2: 8529 / 10000\n",
      "Epoch 3: 8649 / 10000\n",
      "Epoch 4: 8579 / 10000\n",
      "Epoch 5: 8634 / 10000\n",
      "Epoch 6: 8727 / 10000\n",
      "Epoch 7: 8660 / 10000\n",
      "Epoch 8: 8797 / 10000\n",
      "Epoch 9: 9497 / 10000\n",
      "Epoch 10: 9523 / 10000\n",
      "Epoch 11: 9591 / 10000\n",
      "Epoch 12: 9565 / 10000\n",
      "Epoch 13: 9550 / 10000\n",
      "Epoch 14: 9605 / 10000\n",
      "Epoch 15: 9597 / 10000\n",
      "Epoch 16: 9628 / 10000\n",
      "Epoch 17: 9579 / 10000\n",
      "Epoch 18: 9662 / 10000\n",
      "Epoch 19: 9647 / 10000\n",
      "Epoch 20: 9646 / 10000\n",
      "Epoch 21: 9620 / 10000\n",
      "Epoch 22: 9636 / 10000\n",
      "Epoch 23: 9667 / 10000\n",
      "Epoch 24: 9640 / 10000\n",
      "Epoch 25: 9632 / 10000\n",
      "Epoch 26: 9644 / 10000\n",
      "Epoch 27: 9683 / 10000\n",
      "Epoch 28: 9661 / 10000\n",
      "Epoch 29: 9698 / 10000\n"
     ]
    }
   ],
   "source": [
    "ann_mnist4.track_progress(train = mnist_train, mini_batch_size = 10, alpha = 3.0, epochs = 30, test = mnist_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. peak accuracy 96.98% when run on a [784, 200, 150, 100, 10] network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For practical purposes, use a [784, 100, 10] network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_mnist5 = ArtificialNeuralNetwork([784, 100, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 5408 / 10000\n",
      "Epoch 1: 5619 / 10000\n",
      "Epoch 2: 5675 / 10000\n",
      "Epoch 3: 5716 / 10000\n",
      "Epoch 4: 5736 / 10000\n",
      "Epoch 5: 5742 / 10000\n",
      "Epoch 6: 5763 / 10000\n",
      "Epoch 7: 5774 / 10000\n",
      "Epoch 8: 5777 / 10000\n",
      "Epoch 9: 5783 / 10000\n",
      "Epoch 10: 5790 / 10000\n",
      "Epoch 11: 5793 / 10000\n",
      "Epoch 12: 5794 / 10000\n",
      "Epoch 13: 5801 / 10000\n",
      "Epoch 14: 5813 / 10000\n",
      "Epoch 15: 5807 / 10000\n",
      "Epoch 16: 5817 / 10000\n",
      "Epoch 17: 5900 / 10000\n",
      "Epoch 18: 6703 / 10000\n",
      "Epoch 19: 6718 / 10000\n",
      "Epoch 20: 6723 / 10000\n",
      "Epoch 21: 6722 / 10000\n",
      "Epoch 22: 6731 / 10000\n",
      "Epoch 23: 6719 / 10000\n",
      "Epoch 24: 6744 / 10000\n",
      "Epoch 25: 6744 / 10000\n",
      "Epoch 26: 6743 / 10000\n",
      "Epoch 27: 6758 / 10000\n",
      "Epoch 28: 6749 / 10000\n",
      "Epoch 29: 6748 / 10000\n"
     ]
    }
   ],
   "source": [
    "ann_mnist5.track_progress(train = mnist_train, mini_batch_size = 32, alpha = 3.0, epochs = 30, test = mnist_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. peak accuracy 67.58% when run on a [784, 100, 10] network with a mini-batch size of 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start using 1000 train images and validation data (instead of test data) of 5000 images to tune the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_mnist7 = ArtificialNeuralNetwork([784, 100, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 494 / 5000\n",
      "Epoch 1: 484 / 5000\n",
      "Epoch 2: 486 / 5000\n",
      "Epoch 3: 502 / 5000\n",
      "Epoch 4: 493 / 5000\n",
      "Epoch 5: 493 / 5000\n",
      "Epoch 6: 498 / 5000\n",
      "Epoch 7: 485 / 5000\n",
      "Epoch 8: 485 / 5000\n",
      "Epoch 9: 483 / 5000\n",
      "Epoch 10: 489 / 5000\n",
      "Epoch 11: 493 / 5000\n",
      "Epoch 12: 496 / 5000\n",
      "Epoch 13: 503 / 5000\n",
      "Epoch 14: 495 / 5000\n",
      "Epoch 15: 486 / 5000\n",
      "Epoch 16: 480 / 5000\n",
      "Epoch 17: 480 / 5000\n",
      "Epoch 18: 490 / 5000\n",
      "Epoch 19: 481 / 5000\n",
      "Epoch 20: 494 / 5000\n",
      "Epoch 21: 480 / 5000\n",
      "Epoch 22: 486 / 5000\n",
      "Epoch 23: 477 / 5000\n",
      "Epoch 24: 488 / 5000\n",
      "Epoch 25: 492 / 5000\n",
      "Epoch 26: 491 / 5000\n",
      "Epoch 27: 497 / 5000\n"
     ]
    }
   ],
   "source": [
    "ann_mnist6.track_progress(train = mnist_train, mini_batch_size = 10, alpha = 3.0, epochs = 30,\n",
    "                          test = mnist_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_mnist1 = ArtificialNeuralNetwork([784, 30, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 9156 / 10000\n",
      "Epoch 1: 9175 / 10000\n",
      "Epoch 2: 9352 / 10000\n",
      "Epoch 3: 9341 / 10000\n",
      "Epoch 4: 9396 / 10000\n",
      "Epoch 5: 9416 / 10000\n",
      "Epoch 6: 9428 / 10000\n",
      "Epoch 7: 9434 / 10000\n",
      "Epoch 8: 9404 / 10000\n",
      "Epoch 9: 9449 / 10000\n",
      "Epoch 10: 9463 / 10000\n",
      "Epoch 11: 9512 / 10000\n",
      "Epoch 12: 9495 / 10000\n",
      "Epoch 13: 9487 / 10000\n",
      "Epoch 14: 9501 / 10000\n",
      "Epoch 15: 9495 / 10000\n",
      "Epoch 16: 9507 / 10000\n",
      "Epoch 17: 9510 / 10000\n",
      "Epoch 18: 9528 / 10000\n",
      "Epoch 19: 9509 / 10000\n",
      "Epoch 20: 9505 / 10000\n",
      "Epoch 21: 9523 / 10000\n",
      "Epoch 22: 9522 / 10000\n",
      "Epoch 23: 9518 / 10000\n",
      "Epoch 24: 9499 / 10000\n",
      "Epoch 25: 9510 / 10000\n",
      "Epoch 26: 9512 / 10000\n",
      "Epoch 27: 9543 / 10000\n",
      "Epoch 28: 9508 / 10000\n",
      "Epoch 29: 9523 / 10000\n"
     ]
    }
   ],
   "source": [
    "ann_mnist1.track_progress(train = mnist_train, mini_batch_size = 10, alpha = 3.0, epochs = 30, test = mnist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_mnisti = ArtificialNeuralNetwork([784, 30, 10], cross_entropy = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 9386 / 10000\n",
      "Epoch 1: 9488 / 10000\n",
      "Epoch 2: 9531 / 10000\n",
      "Epoch 3: 9560 / 10000\n",
      "Epoch 4: 9528 / 10000\n",
      "Epoch 5: 9545 / 10000\n",
      "Epoch 6: 9575 / 10000\n",
      "Epoch 7: 9573 / 10000\n",
      "Epoch 8: 9543 / 10000\n",
      "Epoch 9: 9619 / 10000\n",
      "Epoch 10: 9627 / 10000\n",
      "Epoch 11: 9596 / 10000\n",
      "Epoch 12: 9604 / 10000\n",
      "Epoch 13: 9599 / 10000\n",
      "Epoch 14: 9617 / 10000\n",
      "Epoch 15: 9607 / 10000\n",
      "Epoch 16: 9581 / 10000\n",
      "Epoch 17: 9594 / 10000\n",
      "Epoch 18: 9602 / 10000\n",
      "Epoch 19: 9565 / 10000\n",
      "Epoch 20: 9603 / 10000\n",
      "Epoch 21: 9603 / 10000\n",
      "Epoch 22: 9626 / 10000\n",
      "Epoch 23: 9620 / 10000\n",
      "Epoch 24: 9619 / 10000\n",
      "Epoch 25: 9626 / 10000\n",
      "Epoch 26: 9598 / 10000\n",
      "Epoch 27: 9610 / 10000\n",
      "Epoch 28: 9590 / 10000\n",
      "Epoch 29: 9581 / 10000\n"
     ]
    }
   ],
   "source": [
    "ann_mnisti.track_progress(train = mnist_train, mini_batch_size = 10, alpha = 0.5, epochs = 30, test = mnist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_mnistl = ArtificialNeuralNetwork([784, 100, 10], cross_entropy = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 9300 / 10000\n",
      "Epoch 2: 9487 / 10000\n",
      "Epoch 3: 9556 / 10000\n",
      "Epoch 4: 9612 / 10000\n",
      "Epoch 5: 9632 / 10000\n",
      "Epoch 6: 9676 / 10000\n",
      "Epoch 7: 9691 / 10000\n",
      "Epoch 8: 9705 / 10000\n",
      "Epoch 9: 9707 / 10000\n",
      "Epoch 10: 9728 / 10000\n",
      "Epoch 11: 9739 / 10000\n",
      "Epoch 12: 9741 / 10000\n",
      "Epoch 13: 9733 / 10000\n",
      "Epoch 14: 9741 / 10000\n",
      "Epoch 15: 9739 / 10000\n",
      "Epoch 16: 9761 / 10000\n",
      "Epoch 17: 9772 / 10000\n",
      "Epoch 18: 9765 / 10000\n",
      "Epoch 19: 9768 / 10000\n",
      "Epoch 20: 9766 / 10000\n",
      "Epoch 21: 9771 / 10000\n",
      "Epoch 22: 9773 / 10000\n",
      "Epoch 23: 9771 / 10000\n",
      "Epoch 24: 9783 / 10000\n",
      "Epoch 25: 9774 / 10000\n",
      "Epoch 26: 9787 / 10000\n",
      "Epoch 27: 9784 / 10000\n",
      "Epoch 28: 9784 / 10000\n",
      "Epoch 29: 9786 / 10000\n",
      "Epoch 30: 9780 / 10000\n",
      "Epoch 31: 9791 / 10000\n",
      "Epoch 32: 9788 / 10000\n",
      "Epoch 33: 9796 / 10000\n",
      "Epoch 34: 9789 / 10000\n",
      "Epoch 35: 9789 / 10000\n",
      "Epoch 36: 9786 / 10000\n",
      "Epoch 37: 9797 / 10000\n",
      "Epoch 38: 9792 / 10000\n",
      "Epoch 39: 9795 / 10000\n",
      "Epoch 40: 9792 / 10000\n",
      "Epoch 41: 9788 / 10000\n",
      "Epoch 42: 9794 / 10000\n",
      "Epoch 43: 9799 / 10000\n",
      "Epoch 44: 9790 / 10000\n",
      "Epoch 45: 9800 / 10000\n",
      "Epoch 46: 9798 / 10000\n",
      "Epoch 47: 9789 / 10000\n",
      "Epoch 48: 9793 / 10000\n",
      "Epoch 49: 9799 / 10000\n",
      "Epoch 50: 9787 / 10000\n",
      "Epoch 51: 9799 / 10000\n",
      "Epoch 52: 9782 / 10000\n",
      "Epoch 53: 9793 / 10000\n",
      "Epoch 54: 9804 / 10000\n",
      "Epoch 55: 9796 / 10000\n",
      "Epoch 56: 9803 / 10000\n",
      "Epoch 57: 9796 / 10000\n",
      "Epoch 58: 9804 / 10000\n",
      "Epoch 59: 9799 / 10000\n",
      "Epoch 60: 9803 / 10000\n"
     ]
    }
   ],
   "source": [
    "ann_mnistl.track_progress(train = mnist_train, mini_batch_size = 10, alpha = 0.1, epochs = 60, lmbda = 5.0, test = mnist_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## max 98.04% accuracy with cross-entropy, weight-initialization, L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
